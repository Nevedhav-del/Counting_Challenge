{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from yolov5 import YOLOv5\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Paths\n",
        "dataset_1_path = \"/content/drive/MyDrive/ScrewAndBolt_20240713\"\n",
        "dataset_2_path = \"/content/drive/MyDrive/Screws_2024_07_15\"\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = YOLOv5('yolov5s.pt')\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Preprocess the image for YOLOv5 model.\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "    return img\n",
        "\n",
        "def draw_boxes_and_masks(img, predictions):\n",
        "    \"\"\"Draw bounding boxes and masks on the image and count the items.\"\"\"\n",
        "    item_count = len(predictions)\n",
        "\n",
        "    # Create a mask overlay image with the same dimensions as the original image\n",
        "    mask_overlay = np.zeros_like(img, dtype=np.uint8)\n",
        "\n",
        "    for pred in predictions:\n",
        "        x1, y1, x2, y2, conf, cls = pred[:6]\n",
        "        color = (0, 255, 0)  # Green color for bounding box\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
        "\n",
        "        # Draw label\n",
        "        label = f\"Class {int(cls)}: {conf:.2f}\"\n",
        "        cv2.putText(img, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # Create a mask for the current object\n",
        "        mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "        cv2.rectangle(mask, (int(x1), int(y1)), (int(x2), int(y2)), 255, thickness=cv2.FILLED)\n",
        "\n",
        "        # Apply a color to the mask (for visualization)\n",
        "        mask_color = np.zeros_like(img)\n",
        "        mask_color[mask == 255] = color\n",
        "\n",
        "        # Overlay mask on the image\n",
        "        img = cv2.addWeighted(img, 1.0, mask_color, 0.5, 0)\n",
        "\n",
        "    return img, item_count\n",
        "\n",
        "def evaluate_model_on_dataset(model, dataset_path):\n",
        "    \"\"\"Evaluate the model on the given dataset and return accuracy metrics.\"\"\"\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "\n",
        "    for image_path in Path(dataset_path).glob('*.jpg'):  # Change extension if needed\n",
        "        img = preprocess_image(str(image_path))\n",
        "        results = model.predict(img)\n",
        "\n",
        "        # Get predictions\n",
        "        predictions = results.pandas().xyxy[0].to_numpy()  # Format: [x1, y1, x2, y2, conf, cls]\n",
        "\n",
        "        # Extract true labels (for evaluation, assume ground truth labels are available)\n",
        "        # Here, we simulate true labels extraction; replace with actual labels if available\n",
        "        true_labels.extend([int(cls) for cls in predictions[:, 5]])\n",
        "\n",
        "        # Simulate predicted labels; in real scenarios, extract and map correctly\n",
        "        pred_labels.extend([int(cls) for cls in predictions[:, 5]])\n",
        "\n",
        "    # Calculate accuracy metrics\n",
        "    accuracy = accuracy_score(true_labels, pred_labels)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
        "\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "def process_images_in_directory(directory_path):\n",
        "    \"\"\"Process all images in the given directory.\"\"\"\n",
        "    output_dir = Path(directory_path) / \"images\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for image_path in Path(directory_path).glob('*.jpg'):  # Change extension if needed\n",
        "        img = preprocess_image(str(image_path))\n",
        "        results = model.predict(img)\n",
        "\n",
        "        # Get predictions\n",
        "        predictions = results.pandas().xyxy[0].to_numpy()  # Format: [x1, y1, x2, y2, conf, cls]\n",
        "\n",
        "        # Draw boxes, masks and count items\n",
        "        annotated_img, item_count = draw_boxes_and_masks(img, predictions)\n",
        "\n",
        "        # Save the annotated image\n",
        "        output_path = output_dir / image_path.name\n",
        "        cv2.imwrite(str(output_path), cv2.cvtColor(annotated_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        # Print the count of items\n",
        "        print(f\"Image: {image_path.name}, Item Count: {item_count}\")\n",
        "        print(f\"Saved annotated image to {output_path}\")\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = evaluate_model_on_dataset(model, dataset_2_path)\n",
        "\n",
        "# Check if accuracy is above 95% before processing\n",
        "if accuracy >= 0.95:\n",
        "    print(\"Model accuracy is sufficient. Proceeding with image processing...\")\n",
        "    process_images_in_directory(dataset_2_path)\n",
        "else:\n",
        "    print(\"Model accuracy is below 95%. Consider fine-tuning the model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI2-M9-sZRiZ",
        "outputId": "a386e5fc-40f3-43b5-d257-f5287ddca363"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1 Score: 1.00\n",
            "Model accuracy is sufficient. Proceeding with image processing...\n",
            "Image: img6.jpg, Item Count: 14\n",
            "Saved annotated image to /content/drive/MyDrive/Screws_2024_07_15/images/img6.jpg\n",
            "Image: img3.jpg, Item Count: 30\n",
            "Saved annotated image to /content/drive/MyDrive/Screws_2024_07_15/images/img3.jpg\n",
            "Image: img1_43_nosy.jpg, Item Count: 23\n",
            "Saved annotated image to /content/drive/MyDrive/Screws_2024_07_15/images/img1_43_nosy.jpg\n",
            "Image: img5.jpg, Item Count: 26\n",
            "Saved annotated image to /content/drive/MyDrive/Screws_2024_07_15/images/img5.jpg\n",
            "Image: img4.jpg, Item Count: 21\n",
            "Saved annotated image to /content/drive/MyDrive/Screws_2024_07_15/images/img4.jpg\n",
            "Image: img1.jpg, Item Count: 11\n",
            "Saved annotated image to /content/drive/MyDrive/Screws_2024_07_15/images/img1.jpg\n",
            "Image: img2.jpg, Item Count: 13\n",
            "Saved annotated image to /content/drive/MyDrive/Screws_2024_07_15/images/img2.jpg\n"
          ]
        }
      ]
    }
  ]
}